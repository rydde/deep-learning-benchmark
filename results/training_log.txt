
========================================
Benchmark Run: 2025-06-22T16:25:48.426152
PyTorch version: 2.7.1+cu128
CUDA available: True
CUDA device: NVIDIA GeForce RTX 5070 Ti
========================================

==============================
Grid search run 1/8: {'lr': 0.001, 'batch_size': 64, 'optimizer_type': 'adam', 'param_id': 'run1'}
Training on cpu with lr=0.001, batch_size=64, optimizer=adam, patience=3
[1, 1] loss: 2.6040
[1, 101] loss: 1.8326
[1, 201] loss: 1.6741
[1, 301] loss: 1.5816
[1, 401] loss: 1.5234
[1, 501] loss: 1.4729
[1, 601] loss: 1.4320
[1, 701] loss: 1.3949
Epoch 1: Test Accuracy: 60.64%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 60.64%
[2, 1] loss: 0.9777
[2, 101] loss: 1.0459
[2, 201] loss: 1.0297
[2, 301] loss: 1.0233
[2, 401] loss: 1.0146
[2, 501] loss: 1.0064
[2, 601] loss: 1.0005
[2, 701] loss: 0.9946
Epoch 2: Test Accuracy: 68.20%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 68.20%
[3, 1] loss: 0.7109
[3, 101] loss: 0.8011
[3, 201] loss: 0.8059
[3, 301] loss: 0.8118
[3, 401] loss: 0.8149
[3, 501] loss: 0.8127
[3, 601] loss: 0.8084
[3, 701] loss: 0.8073
Epoch 3: Test Accuracy: 69.06%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 69.06%
[4, 1] loss: 0.8987
[4, 101] loss: 0.6846
[4, 201] loss: 0.6865
[4, 301] loss: 0.6873
[4, 401] loss: 0.6932
[4, 501] loss: 0.6919
[4, 601] loss: 0.6891
[4, 701] loss: 0.6848
Epoch 4: Test Accuracy: 71.33%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 71.33%
Finished Training in 410.61 seconds
Best Test Accuracy: 71.33% (Epoch 4)

==============================
Grid search run 2/8: {'lr': 0.001, 'batch_size': 64, 'optimizer_type': 'sgd', 'param_id': 'run2'}
Training on cpu with lr=0.001, batch_size=64, optimizer=sgd, patience=3
[1, 1] loss: 2.3898
[1, 101] loss: 2.0439
[1, 201] loss: 1.8906
[1, 301] loss: 1.7915
[1, 401] loss: 1.7314
[1, 501] loss: 1.6827
[1, 601] loss: 1.6462
[1, 701] loss: 1.6100
Epoch 1: Test Accuracy: 50.77%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 50.77%
[2, 1] loss: 1.3497
[2, 101] loss: 1.2643
[2, 201] loss: 1.2637
[2, 301] loss: 1.2590
[2, 401] loss: 1.2543
[2, 501] loss: 1.2470
[2, 601] loss: 1.2379
[2, 701] loss: 1.2273
Epoch 2: Test Accuracy: 57.91%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 57.91%
[3, 1] loss: 0.7670
[3, 101] loss: 1.0295
[3, 201] loss: 1.0315
[3, 301] loss: 1.0320
[3, 401] loss: 1.0333
[3, 501] loss: 1.0367
[3, 601] loss: 1.0311
[3, 701] loss: 1.0279
Epoch 3: Test Accuracy: 59.65%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 59.65%
[4, 1] loss: 0.8211
[4, 101] loss: 0.8586
[4, 201] loss: 0.8610
[4, 301] loss: 0.8622
[4, 401] loss: 0.8692
[4, 501] loss: 0.8697
[4, 601] loss: 0.8688
[4, 701] loss: 0.8686
Epoch 4: Test Accuracy: 62.98%
Model saved to models/best_model_cpu_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 62.98%
Finished Training in 409.50 seconds
Best Test Accuracy: 62.98% (Epoch 4)

==============================
Grid search run 3/8: {'lr': 0.001, 'batch_size': 128, 'optimizer_type': 'adam', 'param_id': 'run3'}
Training on cpu with lr=0.001, batch_size=128, optimizer=adam, patience=3
[1, 1] loss: 2.5612
[1, 101] loss: 1.6728
[1, 201] loss: 1.5189
[1, 301] loss: 1.4204
Epoch 1: Test Accuracy: 58.83%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 58.83%
[2, 1] loss: 1.0227
[2, 101] loss: 1.0272
[2, 201] loss: 1.0125
[2, 301] loss: 0.9836
Epoch 2: Test Accuracy: 64.16%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 64.16%
[3, 1] loss: 0.8566
[3, 101] loss: 0.7877
[3, 201] loss: 0.7981
[3, 301] loss: 0.7945
Epoch 3: Test Accuracy: 69.80%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 69.80%
[4, 1] loss: 0.6239
[4, 101] loss: 0.6422
[4, 201] loss: 0.6508
[4, 301] loss: 0.6596
Epoch 4: Test Accuracy: 72.57%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 72.57%
Finished Training in 314.01 seconds
Best Test Accuracy: 72.57% (Epoch 4)

==============================
Grid search run 4/8: {'lr': 0.001, 'batch_size': 128, 'optimizer_type': 'sgd', 'param_id': 'run4'}
Training on cpu with lr=0.001, batch_size=128, optimizer=sgd, patience=3
[1, 1] loss: 2.4969
[1, 101] loss: 2.0044
[1, 201] loss: 1.8327
[1, 301] loss: 1.7367
Epoch 1: Test Accuracy: 48.73%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 48.73%
[2, 1] loss: 1.3464
[2, 101] loss: 1.3380
[2, 201] loss: 1.3235
[2, 301] loss: 1.3053
Epoch 2: Test Accuracy: 53.45%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 53.45%
[3, 1] loss: 0.9446
[3, 101] loss: 1.1239
[3, 201] loss: 1.1166
[3, 301] loss: 1.1118
Epoch 3: Test Accuracy: 56.92%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 56.92%
[4, 1] loss: 0.9232
[4, 101] loss: 0.9386
[4, 201] loss: 0.9450
[4, 301] loss: 0.9503
Epoch 4: Test Accuracy: 58.78%
Model saved to models/best_model_cpu_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 58.78%
Finished Training in 304.37 seconds
Best Test Accuracy: 58.78% (Epoch 4)

==============================
Grid search run 5/8: {'lr': 0.01, 'batch_size': 64, 'optimizer_type': 'adam', 'param_id': 'run5'}
Training on cpu with lr=0.01, batch_size=64, optimizer=adam, patience=3
[1, 1] loss: 2.6537
[1, 101] loss: 2.3227
[1, 201] loss: 2.1562
[1, 301] loss: 2.0707
[1, 401] loss: 1.9816
[1, 501] loss: 1.8956
[1, 601] loss: 1.8368
[1, 701] loss: 1.7815
Epoch 1: Test Accuracy: 46.23%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 46.23%
[2, 1] loss: 1.3065
[2, 101] loss: 1.3492
[2, 201] loss: 1.3329
[2, 301] loss: 1.3104
[2, 401] loss: 1.2865
[2, 501] loss: 1.2673
[2, 601] loss: 1.2499
[2, 701] loss: 1.2328
Epoch 2: Test Accuracy: 61.43%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 61.43%
[3, 1] loss: 1.0643
[3, 101] loss: 1.0329
[3, 201] loss: 1.0323
[3, 301] loss: 1.0250
[3, 401] loss: 1.0159
[3, 501] loss: 1.0072
[3, 601] loss: 0.9957
[3, 701] loss: 0.9900
Epoch 3: Test Accuracy: 66.76%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 66.76%
[4, 1] loss: 0.7423
[4, 101] loss: 0.8328
[4, 201] loss: 0.8336
[4, 301] loss: 0.8374
[4, 401] loss: 0.8392
[4, 501] loss: 0.8383
[4, 601] loss: 0.8383
[4, 701] loss: 0.8333
Epoch 4: Test Accuracy: 69.17%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 69.17%
Finished Training in 436.00 seconds
Best Test Accuracy: 69.17% (Epoch 4)

==============================
Grid search run 6/8: {'lr': 0.01, 'batch_size': 64, 'optimizer_type': 'sgd', 'param_id': 'run6'}
Training on cpu with lr=0.01, batch_size=64, optimizer=sgd, patience=3
[1, 1] loss: 2.4524
[1, 101] loss: 2.1273
[1, 201] loss: 1.9252
[1, 301] loss: 1.8046
[1, 401] loss: 1.7385
[1, 501] loss: 1.6923
[1, 601] loss: 1.6494
[1, 701] loss: 1.6035
Epoch 1: Test Accuracy: 57.49%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 57.49%
[2, 1] loss: 1.0374
[2, 101] loss: 1.2235
[2, 201] loss: 1.2168
[2, 301] loss: 1.2099
[2, 401] loss: 1.1949
[2, 501] loss: 1.1767
[2, 601] loss: 1.1604
[2, 701] loss: 1.1499
Epoch 2: Test Accuracy: 64.90%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 64.90%
[3, 1] loss: 0.8690
[3, 101] loss: 0.9492
[3, 201] loss: 0.9325
[3, 301] loss: 0.9340
[3, 401] loss: 0.9371
[3, 501] loss: 0.9294
[3, 601] loss: 0.9211
[3, 701] loss: 0.9187
Epoch 3: Test Accuracy: 69.04%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 69.04%
[4, 1] loss: 0.7112
[4, 101] loss: 0.7512
[4, 201] loss: 0.7357
[4, 301] loss: 0.7483
[4, 401] loss: 0.7600
[4, 501] loss: 0.7565
[4, 601] loss: 0.7563
[4, 701] loss: 0.7525
Epoch 4: Test Accuracy: 70.51%
Model saved to models/best_model_cpu_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 70.51%
Finished Training in 413.72 seconds
Best Test Accuracy: 70.51% (Epoch 4)

==============================
Grid search run 7/8: {'lr': 0.01, 'batch_size': 128, 'optimizer_type': 'adam', 'param_id': 'run7'}
Training on cpu with lr=0.01, batch_size=128, optimizer=adam, patience=3
[1, 1] loss: 2.6215
[1, 101] loss: 2.1983
[1, 201] loss: 1.9509
[1, 301] loss: 1.8095
Epoch 1: Test Accuracy: 48.80%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 48.80%
[2, 1] loss: 1.3498
[2, 101] loss: 1.2624
[2, 201] loss: 1.2188
[2, 301] loss: 1.1834
Epoch 2: Test Accuracy: 60.46%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 60.46%
[3, 1] loss: 1.0177
[3, 101] loss: 0.9602
[3, 201] loss: 0.9442
[3, 301] loss: 0.9300
Epoch 3: Test Accuracy: 68.82%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 68.82%
[4, 1] loss: 0.6940
[4, 101] loss: 0.7817
[4, 201] loss: 0.7796
[4, 301] loss: 0.7736
Epoch 4: Test Accuracy: 71.68%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 71.68%
Finished Training in 311.07 seconds
Best Test Accuracy: 71.68% (Epoch 4)

==============================
Grid search run 8/8: {'lr': 0.01, 'batch_size': 128, 'optimizer_type': 'sgd', 'param_id': 'run8'}
Training on cpu with lr=0.01, batch_size=128, optimizer=sgd, patience=3
[1, 1] loss: 2.5733
[1, 101] loss: 1.8858
[1, 201] loss: 1.7089
[1, 301] loss: 1.6087
Epoch 1: Test Accuracy: 55.02%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 55.02%
[2, 1] loss: 1.1035
[2, 101] loss: 1.1374
[2, 201] loss: 1.1250
[2, 301] loss: 1.1063
Epoch 2: Test Accuracy: 63.18%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 63.18%
[3, 1] loss: 0.8754
[3, 101] loss: 0.8813
[3, 201] loss: 0.8758
[3, 301] loss: 0.8734
Epoch 3: Test Accuracy: 65.73%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 65.73%
[4, 1] loss: 0.7586
[4, 101] loss: 0.6900
[4, 201] loss: 0.6992
[4, 301] loss: 0.7090
Epoch 4: Test Accuracy: 66.71%
Model saved to models/best_model_cpu_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 66.71%
Finished Training in 305.18 seconds
Best Test Accuracy: 66.71% (Epoch 4)

==============================
Grid search run 1/8: {'lr': 0.001, 'batch_size': 64, 'optimizer_type': 'adam', 'param_id': 'run1'}
Training on cuda with lr=0.001, batch_size=64, optimizer=adam, patience=3
[1, 1] loss: 2.4227
[1, 101] loss: 1.7914
[1, 201] loss: 1.6612
[1, 301] loss: 1.5903
[1, 401] loss: 1.5287
[1, 501] loss: 1.4739
[1, 601] loss: 1.4300
[1, 701] loss: 1.3946
Epoch 1: Test Accuracy: 58.84%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 58.84%
[2, 1] loss: 1.0442
[2, 101] loss: 1.0452
[2, 201] loss: 1.0306
[2, 301] loss: 1.0287
[2, 401] loss: 1.0210
[2, 501] loss: 1.0124
[2, 601] loss: 1.0049
[2, 701] loss: 0.9912
Epoch 2: Test Accuracy: 65.14%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 65.14%
[3, 1] loss: 1.0405
[3, 101] loss: 0.8234
[3, 201] loss: 0.8268
[3, 301] loss: 0.8219
[3, 401] loss: 0.8291
[3, 501] loss: 0.8232
[3, 601] loss: 0.8176
[3, 701] loss: 0.8158
Epoch 3: Test Accuracy: 69.42%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 69.42%
[4, 1] loss: 0.6847
[4, 101] loss: 0.6677
[4, 201] loss: 0.6783
[4, 301] loss: 0.6881
[4, 401] loss: 0.6909
[4, 501] loss: 0.6909
[4, 601] loss: 0.6902
[4, 701] loss: 0.6879
Epoch 4: Test Accuracy: 70.82%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizeradam_paramidrun1.pth with accuracy 70.82%
Finished Training in 43.75 seconds
Best Test Accuracy: 70.82% (Epoch 4)

==============================
Grid search run 2/8: {'lr': 0.001, 'batch_size': 64, 'optimizer_type': 'sgd', 'param_id': 'run2'}
Training on cuda with lr=0.001, batch_size=64, optimizer=sgd, patience=3
[1, 1] loss: 2.4893
[1, 101] loss: 2.0737
[1, 201] loss: 1.9273
[1, 301] loss: 1.8261
[1, 401] loss: 1.7637
[1, 501] loss: 1.7129
[1, 601] loss: 1.6733
[1, 701] loss: 1.6363
Epoch 1: Test Accuracy: 51.51%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 51.51%
[2, 1] loss: 1.2464
[2, 101] loss: 1.3155
[2, 201] loss: 1.2987
[2, 301] loss: 1.2963
[2, 401] loss: 1.2883
[2, 501] loss: 1.2792
[2, 601] loss: 1.2757
[2, 701] loss: 1.2695
Epoch 2: Test Accuracy: 55.58%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 55.58%
[3, 1] loss: 1.1209
[3, 101] loss: 1.1035
[3, 201] loss: 1.0872
[3, 301] loss: 1.0769
[3, 401] loss: 1.0725
[3, 501] loss: 1.0729
[3, 601] loss: 1.0707
[3, 701] loss: 1.0699
Epoch 3: Test Accuracy: 59.59%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 59.59%
[4, 1] loss: 0.9179
[4, 101] loss: 0.8823
[4, 201] loss: 0.8937
[4, 301] loss: 0.9030
[4, 401] loss: 0.9036
[4, 501] loss: 0.9020
[4, 601] loss: 0.9048
[4, 701] loss: 0.9062
Epoch 4: Test Accuracy: 60.90%
Model saved to models/best_model_cuda_lr0.001_batch64_optimizersgd_paramidrun2.pth with accuracy 60.90%
Finished Training in 41.11 seconds
Best Test Accuracy: 60.90% (Epoch 4)

==============================
Grid search run 3/8: {'lr': 0.001, 'batch_size': 128, 'optimizer_type': 'adam', 'param_id': 'run3'}
Training on cuda with lr=0.001, batch_size=128, optimizer=adam, patience=3
[1, 1] loss: 2.5680
[1, 101] loss: 1.6842
[1, 201] loss: 1.5402
[1, 301] loss: 1.4419
Epoch 1: Test Accuracy: 57.33%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 57.33%
[2, 1] loss: 1.0331
[2, 101] loss: 1.0381
[2, 201] loss: 1.0185
[2, 301] loss: 0.9975
Epoch 2: Test Accuracy: 67.51%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 67.51%
[3, 1] loss: 0.6807
[3, 101] loss: 0.8009
[3, 201] loss: 0.7985
[3, 301] loss: 0.8063
Epoch 3: Test Accuracy: 68.82%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 68.82%
[4, 1] loss: 0.6235
[4, 101] loss: 0.6601
[4, 201] loss: 0.6739
[4, 301] loss: 0.6715
Epoch 4: Test Accuracy: 71.62%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizeradam_paramidrun3.pth with accuracy 71.62%
Finished Training in 29.18 seconds
Best Test Accuracy: 71.62% (Epoch 4)

==============================
Grid search run 4/8: {'lr': 0.001, 'batch_size': 128, 'optimizer_type': 'sgd', 'param_id': 'run4'}
Training on cuda with lr=0.001, batch_size=128, optimizer=sgd, patience=3
[1, 1] loss: 2.6738
[1, 101] loss: 2.0083
[1, 201] loss: 1.8153
[1, 301] loss: 1.7210
Epoch 1: Test Accuracy: 48.35%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 48.35%
[2, 1] loss: 1.4371
[2, 101] loss: 1.3376
[2, 201] loss: 1.3189
[2, 301] loss: 1.3091
Epoch 2: Test Accuracy: 52.93%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 52.93%
[3, 1] loss: 1.2778
[3, 101] loss: 1.1257
[3, 201] loss: 1.1077
[3, 301] loss: 1.1092
Epoch 3: Test Accuracy: 56.71%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 56.71%
[4, 1] loss: 0.9318
[4, 101] loss: 0.9514
[4, 201] loss: 0.9474
[4, 301] loss: 0.9432
Epoch 4: Test Accuracy: 58.86%
Model saved to models/best_model_cuda_lr0.001_batch128_optimizersgd_paramidrun4.pth with accuracy 58.86%
Finished Training in 28.15 seconds
Best Test Accuracy: 58.86% (Epoch 4)

==============================
Grid search run 5/8: {'lr': 0.01, 'batch_size': 64, 'optimizer_type': 'adam', 'param_id': 'run5'}
Training on cuda with lr=0.01, batch_size=64, optimizer=adam, patience=3
[1, 1] loss: 2.5303
[1, 101] loss: 2.4594
[1, 201] loss: 2.1782
[1, 301] loss: 2.0307
[1, 401] loss: 1.9271
[1, 501] loss: 1.8506
[1, 601] loss: 1.7866
[1, 701] loss: 1.7319
Epoch 1: Test Accuracy: 53.23%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 53.23%
[2, 1] loss: 1.0357
[2, 101] loss: 1.3050
[2, 201] loss: 1.2650
[2, 301] loss: 1.2443
[2, 401] loss: 1.2204
[2, 501] loss: 1.2029
[2, 601] loss: 1.1847
[2, 701] loss: 1.1708
Epoch 2: Test Accuracy: 63.16%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 63.16%
[3, 1] loss: 1.0229
[3, 101] loss: 0.9790
[3, 201] loss: 0.9627
[3, 301] loss: 0.9669
[3, 401] loss: 0.9552
[3, 501] loss: 0.9530
[3, 601] loss: 0.9555
[3, 701] loss: 0.9468
Epoch 3: Test Accuracy: 67.02%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 67.02%
[4, 1] loss: 0.7390
[4, 101] loss: 0.7840
[4, 201] loss: 0.7914
[4, 301] loss: 0.7998
[4, 401] loss: 0.8005
[4, 501] loss: 0.7934
[4, 601] loss: 0.7950
[4, 701] loss: 0.7944
Epoch 4: Test Accuracy: 69.80%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizeradam_paramidrun5.pth with accuracy 69.80%
Finished Training in 42.50 seconds
Best Test Accuracy: 69.80% (Epoch 4)

==============================
Grid search run 6/8: {'lr': 0.01, 'batch_size': 64, 'optimizer_type': 'sgd', 'param_id': 'run6'}
Training on cuda with lr=0.01, batch_size=64, optimizer=sgd, patience=3
[1, 1] loss: 2.6364
[1, 101] loss: 2.0858
[1, 201] loss: 1.9317
[1, 301] loss: 1.8303
[1, 401] loss: 1.7550
[1, 501] loss: 1.6973
[1, 601] loss: 1.6515
[1, 701] loss: 1.6087
Epoch 1: Test Accuracy: 54.56%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 54.56%
[2, 1] loss: 1.3422
[2, 101] loss: 1.2118
[2, 201] loss: 1.2005
[2, 301] loss: 1.1908
[2, 401] loss: 1.1803
[2, 501] loss: 1.1658
[2, 601] loss: 1.1547
[2, 701] loss: 1.1454
Epoch 2: Test Accuracy: 63.03%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 63.03%
[3, 1] loss: 1.1826
[3, 101] loss: 0.9415
[3, 201] loss: 0.9403
[3, 301] loss: 0.9377
[3, 401] loss: 0.9390
[3, 501] loss: 0.9350
[3, 601] loss: 0.9338
[3, 701] loss: 0.9328
Epoch 3: Test Accuracy: 66.24%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 66.24%
[4, 1] loss: 0.9792
[4, 101] loss: 0.7643
[4, 201] loss: 0.7629
[4, 301] loss: 0.7717
[4, 401] loss: 0.7696
[4, 501] loss: 0.7685
[4, 601] loss: 0.7676
[4, 701] loss: 0.7679
Epoch 4: Test Accuracy: 69.77%
Model saved to models/best_model_cuda_lr0.01_batch64_optimizersgd_paramidrun6.pth with accuracy 69.77%
Finished Training in 40.81 seconds
Best Test Accuracy: 69.77% (Epoch 4)

==============================
Grid search run 7/8: {'lr': 0.01, 'batch_size': 128, 'optimizer_type': 'adam', 'param_id': 'run7'}
Training on cuda with lr=0.01, batch_size=128, optimizer=adam, patience=3
[1, 1] loss: 2.5840
[1, 101] loss: 2.1582
[1, 201] loss: 1.9230
[1, 301] loss: 1.7951
Epoch 1: Test Accuracy: 50.28%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 50.28%
[2, 1] loss: 1.1672
[2, 101] loss: 1.3029
[2, 201] loss: 1.2681
[2, 301] loss: 1.2277
Epoch 2: Test Accuracy: 60.57%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 60.57%
[3, 1] loss: 0.9695
[3, 101] loss: 1.0218
[3, 201] loss: 1.0042
[3, 301] loss: 0.9831
Epoch 3: Test Accuracy: 66.74%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 66.74%
[4, 1] loss: 0.7655
[4, 101] loss: 0.8101
[4, 201] loss: 0.8177
[4, 301] loss: 0.8078
Epoch 4: Test Accuracy: 69.58%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizeradam_paramidrun7.pth with accuracy 69.58%
Finished Training in 28.02 seconds
Best Test Accuracy: 69.58% (Epoch 4)

==============================
Grid search run 8/8: {'lr': 0.01, 'batch_size': 128, 'optimizer_type': 'sgd', 'param_id': 'run8'}
Training on cuda with lr=0.01, batch_size=128, optimizer=sgd, patience=3
[1, 1] loss: 2.6485
[1, 101] loss: 1.8724
[1, 201] loss: 1.6923
[1, 301] loss: 1.5945
Epoch 1: Test Accuracy: 54.41%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 54.41%
[2, 1] loss: 1.0553
[2, 101] loss: 1.1657
[2, 201] loss: 1.1501
[2, 301] loss: 1.1219
Epoch 2: Test Accuracy: 64.05%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 64.05%
[3, 1] loss: 0.7434
[3, 101] loss: 0.8902
[3, 201] loss: 0.8877
[3, 301] loss: 0.8876
Epoch 3: Test Accuracy: 66.03%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 66.03%
[4, 1] loss: 0.8781
[4, 101] loss: 0.7240
[4, 201] loss: 0.7291
[4, 301] loss: 0.7309
Epoch 4: Test Accuracy: 68.84%
Model saved to models/best_model_cuda_lr0.01_batch128_optimizersgd_paramidrun8.pth with accuracy 68.84%
Finished Training in 27.77 seconds
Best Test Accuracy: 68.84% (Epoch 4)
Benchmark Results: {'cpu': [{'training_time': 410.61311054229736, 'best_accuracy': 71.33, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 64, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run1'}}, {'training_time': 409.4980664253235, 'best_accuracy': 62.98, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 64, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run2'}}, {'training_time': 314.0131962299347, 'best_accuracy': 72.57, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 128, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run3'}}, {'training_time': 304.37348103523254, 'best_accuracy': 58.78, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 128, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run4'}}, {'training_time': 436.00380873680115, 'best_accuracy': 69.17, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 64, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run5'}}, {'training_time': 413.7200057506561, 'best_accuracy': 70.51, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 64, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run6'}}, {'training_time': 311.0740957260132, 'best_accuracy': 71.68, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 128, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run7'}}, {'training_time': 305.17641139030457, 'best_accuracy': 66.71, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 128, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run8'}}], 'gpu': [{'training_time': 43.75103235244751, 'best_accuracy': 70.82, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 64, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run1'}}, {'training_time': 41.11025857925415, 'best_accuracy': 60.9, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 64, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run2'}}, {'training_time': 29.184529304504395, 'best_accuracy': 71.62, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 128, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run3'}}, {'training_time': 28.15298557281494, 'best_accuracy': 58.86, 'best_epoch': 4, 'hyperparameters': {'lr': 0.001, 'batch': 128, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run4'}}, {'training_time': 42.49998688697815, 'best_accuracy': 69.8, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 64, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run5'}}, {'training_time': 40.809659242630005, 'best_accuracy': 69.77, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 64, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run6'}}, {'training_time': 28.017334461212158, 'best_accuracy': 69.58, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 128, 'optimizer': 'adam', 'patience': 3, 'paramid': 'run7'}}, {'training_time': 27.766213178634644, 'best_accuracy': 68.84, 'best_epoch': 4, 'hyperparameters': {'lr': 0.01, 'batch': 128, 'optimizer': 'sgd', 'patience': 3, 'paramid': 'run8'}}]}
